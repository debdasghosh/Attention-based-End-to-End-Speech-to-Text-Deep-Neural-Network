{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4P2_debdasg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5goinUtrYV5t"
      },
      "source": [
        "## Mount Google Drive For Saving Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dadEBl-vDw1V",
        "outputId": "60ff74af-0cba-493d-bbd1-d63d7866e1b6"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhainTIHYjJB"
      },
      "source": [
        "## Download Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFIOmTg6D8Pi",
        "outputId": "7c22f6e9-5528-466f-9b8f-7342f257e268"
      },
      "source": [
        "! mkdir ~/.kaggle\r\n",
        "! cp kaggle.json ~/.kaggle/\r\n",
        "!kaggle competitions download -c 11-785-fall-20-homework-4-part-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "Downloading train.npy.zip to /content\n",
            "100% 3.35G/3.36G [00:45<00:00, 87.9MB/s]\n",
            "100% 3.36G/3.36G [00:45<00:00, 79.3MB/s]\n",
            "Downloading dev.npy.zip to /content\n",
            " 95% 173M/182M [00:03<00:00, 46.3MB/s]\n",
            "100% 182M/182M [00:03<00:00, 47.9MB/s]\n",
            "Downloading test.npy.zip to /content\n",
            " 93% 170M/183M [00:04<00:00, 26.2MB/s]\n",
            "100% 183M/183M [00:04<00:00, 44.8MB/s]\n",
            "Downloading train_transcripts.npy.zip to /content\n",
            "  0% 0.00/3.76M [00:00<?, ?B/s]\n",
            "100% 3.76M/3.76M [00:00<00:00, 124MB/s]\n",
            "Downloading sample.csv to /content\n",
            "  0% 0.00/16.8k [00:00<?, ?B/s]\n",
            "100% 16.8k/16.8k [00:00<00:00, 18.6MB/s]\n",
            "Downloading dev_transcripts.npy to /content\n",
            "  0% 0.00/784k [00:00<?, ?B/s]\n",
            "100% 784k/784k [00:00<00:00, 50.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJurIWOWEE2P",
        "outputId": "cdd204e5-2480-4236-a344-3171b8197160"
      },
      "source": [
        "!unzip dev.npy.zip\r\n",
        "!unzip train.npy.zip\r\n",
        "!unzip train_transcripts.npy.zip\r\n",
        "!unzip test.npy.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  dev.npy.zip\n",
            "  inflating: dev.npy                 \n",
            "Archive:  train.npy.zip\n",
            "  inflating: train.npy               \n",
            "Archive:  train_transcripts.npy.zip\n",
            "  inflating: train_transcripts.npy   \n",
            "Archive:  test.npy.zip\n",
            "  inflating: test.npy                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqsRBzDUYnXA"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyobQuWFEGY7"
      },
      "source": [
        "import time\r\n",
        "import os\r\n",
        "import csv\r\n",
        "from datetime import datetime\r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.nn.utils as utils\r\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\r\n",
        "import torch.nn.utils.rnn as rnn\r\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\r\n",
        "import torch.optim as optim\r\n",
        "import torch.optim.lr_scheduler\r\n",
        "from torchvision import datasets, transforms\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "\r\n",
        "from matplotlib.lines import Line2D\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import matplotlib.image as mpimg\r\n",
        "from torch.distributions.gumbel import Gumbel\r\n",
        "import pickle as pk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF8UExa5YsMU"
      },
      "source": [
        "## Set Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmHjetCTRPa0"
      },
      "source": [
        "class Args():\r\n",
        "  def __init__(self):\r\n",
        "    self.data_dir='./'\r\n",
        "    self.weights_dir='/content/drive/My Drive'\r\n",
        "    self.lr=1e-3\r\n",
        "    self.clip=0.25\r\n",
        "    self.epochs=30\r\n",
        "    self.train_batch_size=20\r\n",
        "    self.dev_batch_size=1\r\n",
        "    self.hidden_dim = 256\r\n",
        "    self.context_dim=128\r\n",
        "    self.key_query_dim=128\r\n",
        "    self.listener_feature_dim=512\r\n",
        "    self.max_iters=600\r\n",
        "    self.dropout=0.2\r\n",
        "    self.dropouth=0.1\r\n",
        "    self.dropouti=0.3\r\n",
        "    self.seed=11785\r\n",
        "    self.cuda = True\r\n",
        "    self.log_interval=40\r\n",
        "    self.wdecay=1.2e-6\r\n",
        "\r\n",
        "\r\n",
        "args = Args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoo_oo4lYwSd"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ThySkgzHzK9"
      },
      "source": [
        "def levenshtein(seq1, seq2):\r\n",
        "    size_x = len(seq1) + 1\r\n",
        "    size_y = len(seq2) + 1\r\n",
        "    matrix = np.zeros ((size_x, size_y))\r\n",
        "    for x in range(size_x):\r\n",
        "        matrix [x, 0] = x\r\n",
        "    for y in range(size_y):\r\n",
        "        matrix [0, y] = y\r\n",
        "\r\n",
        "    for x in range(1, size_x):\r\n",
        "        for y in range(1, size_y):\r\n",
        "            if seq1[x-1] == seq2[y-1]:\r\n",
        "                matrix [x,y] = min(\r\n",
        "                    matrix[x-1, y] + 1,\r\n",
        "                    matrix[x-1, y-1],\r\n",
        "                    matrix[x, y-1] + 1\r\n",
        "                )\r\n",
        "            else:\r\n",
        "                matrix [x,y] = min(\r\n",
        "                    matrix[x-1,y] + 1,\r\n",
        "                    matrix[x-1,y-1] + 1,\r\n",
        "                    matrix[x,y-1] + 1\r\n",
        "                )\r\n",
        "    return (matrix[size_x - 1, size_y - 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-SsTe7pH3XW"
      },
      "source": [
        "def to_float_tensor(numpy_array):\r\n",
        "    # Numpy array -> Tensor\r\n",
        "    return torch.from_numpy(numpy_array).float()\r\n",
        "\r\n",
        "def to_long_tensor(numpy_array):\r\n",
        "    # Numpy array -> Tensor\r\n",
        "    return torch.from_numpy(numpy_array).long()\r\n",
        "\r\n",
        "def to_int_tensor(numpy_array):\r\n",
        "    # Numpy array -> Tensor\r\n",
        "    return torch.from_numpy(numpy_array).int()\r\n",
        "\r\n",
        "def to_tensor(numpy_array):\r\n",
        "    # Numpy array -> Tensor\r\n",
        "    return torch.from_numpy(numpy_array)\r\n",
        "\r\n",
        "def to_np(x):\r\n",
        "    return x.data.cpu().numpy()\r\n",
        "\r\n",
        "def to_variable(tensor):\r\n",
        "    # Tensor -> Variable (on GPU if possible)\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        # Tensor -> GPU Tensor\r\n",
        "        tensor = tensor.cuda()\r\n",
        "    return torch.autograd.Variable(tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2zbfiZByMsr"
      },
      "source": [
        "def plot_grad_flow(named_parameters, path):\r\n",
        "    ave_grads = []\r\n",
        "    max_grads = []\r\n",
        "    layers = []\r\n",
        "    for n, p in named_parameters:\r\n",
        "        if(p.requires_grad) and (\"bias\" not in n):\r\n",
        "            if(p is not None):\r\n",
        "                layers.append(n)\r\n",
        "                ave_grads.append(p.grad.abs().mean())\r\n",
        "                max_grads.append(p.grad.abs().max())\r\n",
        "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\r\n",
        "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\r\n",
        "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\r\n",
        "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\r\n",
        "    plt.xlim(left=0, right=len(ave_grads))\r\n",
        "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\r\n",
        "    plt.xlabel(\"Layers\")\r\n",
        "    plt.ylabel(\"average gradient\")\r\n",
        "    plt.title(\"Gradient flow\")\r\n",
        "    #plt.tight_layout()\r\n",
        "    plt.grid(True)\r\n",
        "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\r\n",
        "                Line2D([0], [0], color=\"b\", lw=4),\r\n",
        "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\r\n",
        "    plt.show()\r\n",
        "    plt.savefig(path)\r\n",
        "    return plt, max_grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2jNi8AJ3vAN"
      },
      "source": [
        "def cer(s1, s2):\r\n",
        "    s1, s2, = s1.replace(' ', ''), s2.replace(' ', '')\r\n",
        "    return levenshtein(s1, s2)\r\n",
        "\r\n",
        "def labels2str(labels, label_sizes):\r\n",
        "    output = []\r\n",
        "    for l, s in zip(labels, label_sizes):\r\n",
        "        output.append(\"\".join(idx2chr[i] for i in l[:s]))\r\n",
        "    return output\r\n",
        "\r\n",
        "def label_list_to_str(labels):\r\n",
        "    output = []\r\n",
        "    for l in labels:\r\n",
        "        output.append(\"\".join(idx2chr[i] for i in l))\r\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAN2pLTx3yND"
      },
      "source": [
        "def greedy_decode(probs):\r\n",
        "    out = []\r\n",
        "    for prob in probs:\r\n",
        "        s = []\r\n",
        "        for step in prob:\r\n",
        "            idx = torch.argmax(step).item()\r\n",
        "            c = idx2chr[idx]\r\n",
        "            s.append(c)\r\n",
        "            if c == '<eos>':\r\n",
        "                break\r\n",
        "        out.append(\"\".join(s))\r\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mE2ex1CY6bS"
      },
      "source": [
        "## Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu0tl1QkFDvU"
      },
      "source": [
        "class Speech2Text_Dataset(Dataset):\r\n",
        "    def __init__(self, speech, text=None):\r\n",
        "        self.speech = speech\r\n",
        "        self.text = text\r\n",
        "        if text is not None:\r\n",
        "            self.total_labels = sum(len(y) for y in text)\r\n",
        "        else:\r\n",
        "            self.total_labels = -1\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        frames = self.speech[idx]\r\n",
        "        if self.text is None:\r\n",
        "            labels = [-1]\r\n",
        "        else:\r\n",
        "            text = self.text[idx].tolist()\r\n",
        "            text = b' '.join(text)\r\n",
        "            text = text.decode(\"utf-8\")\r\n",
        "            labels = [chr2idx[c] for c in str(text)]\r\n",
        "            labels = labels + [chr2idx['<eos>']]\r\n",
        "        return to_float_tensor(frames), to_int_tensor(np.array(labels))\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return self.speech.shape[0]\r\n",
        "\r\n",
        "\r\n",
        "def Speech2Text_collate(batch):\r\n",
        "    batch_size = len(batch)\r\n",
        "    batch = sorted(batch, key=lambda b: b[0].size(0), reverse=True) \r\n",
        "    max_seq_len = batch[0][0].size(0)\r\n",
        "    channels = batch[0][0].size(1)\r\n",
        "    pack = torch.zeros(max_seq_len, batch_size, channels)\r\n",
        "    seq_sizes = []\r\n",
        "    max_label_len = max(label.size(0) for (f, label) in batch)\r\n",
        "    all_labels = torch.zeros(batch_size, max_label_len).long()\r\n",
        "    label_sizes = torch.zeros(batch_size).int()\r\n",
        "    for i, (frames, label) in enumerate(batch):\r\n",
        "        seq_size = frames.size(0)\r\n",
        "        seq_sizes.append(seq_size)\r\n",
        "\r\n",
        "        labele_size = label.size(0)\r\n",
        "        label_sizes[i] = labele_size\r\n",
        "\r\n",
        "        pack[:seq_size, i, :] = frames\r\n",
        "        all_labels[i, :labele_size] = label\r\n",
        "    return pack, seq_sizes, all_labels, label_sizes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-HLdeKfEPhs"
      },
      "source": [
        "speech_train = np.load('train.npy', allow_pickle=True, encoding='bytes')\r\n",
        "speech_valid = np.load('dev.npy', allow_pickle=True, encoding='bytes')\r\n",
        "speech_test = np.load('test.npy', allow_pickle=True, encoding='bytes')\r\n",
        "\r\n",
        "transcript_train = np.load('train_transcripts.npy', allow_pickle=True,encoding='bytes')\r\n",
        "transcript_valid = np.load('dev_transcripts.npy', allow_pickle=True,encoding='bytes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7Y5hBVjEUHu",
        "outputId": "2d9ff0bc-c759-4836-982a-74ed4a76715a"
      },
      "source": [
        "vocab = sorted(list(set(''.join([''.join([p.decode(\"utf-8\") for p in transcript_train[i]]) for i in range(transcript_train.shape[0])]))))\r\n",
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"'\",\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mOc9q_yEV1Q"
      },
      "source": [
        "letter_list = ['<sos>',\r\n",
        " 'a',\r\n",
        " 'b',\r\n",
        " 'c',\r\n",
        " 'd',\r\n",
        " 'e',\r\n",
        " 'f',\r\n",
        " 'g',\r\n",
        " 'h',\r\n",
        " 'i',\r\n",
        " 'j',\r\n",
        " 'k',\r\n",
        " 'l',\r\n",
        " 'm',\r\n",
        " 'n',\r\n",
        " 'o',\r\n",
        " 'p',\r\n",
        " 'q',\r\n",
        " 'r',\r\n",
        " 's',\r\n",
        " 't',\r\n",
        " 'u',\r\n",
        " 'v',\r\n",
        " 'w',\r\n",
        " 'x',\r\n",
        " 'y',\r\n",
        " 'z', \"'\", '\"', ' ','<eos>']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TND0gcx9EkIj"
      },
      "source": [
        "def create_dictionaries(letter_list):\r\n",
        "    letter2index = dict({letter_list[i]:i for i in range(len(letter_list))})\r\n",
        "    index2letter = dict({i:letter_list[i] for i in range(len(letter_list))})\r\n",
        "    return letter2index, index2letter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvYZmxP5E7ai"
      },
      "source": [
        "chr2idx, idx2chr = create_dictionaries(letter_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft3ufqKBFILq"
      },
      "source": [
        "kwargs = {'num_workers': 3, 'pin_memory': True} if args.cuda else {}\r\n",
        "train_loader = torch.utils.data.DataLoader(\r\n",
        "    Speech2Text_Dataset(speech_train, transcript_train),\r\n",
        "    batch_size=args.train_batch_size, shuffle=True, collate_fn=Speech2Text_collate, **kwargs)\r\n",
        "dev_loader = torch.utils.data.DataLoader(\r\n",
        "    Speech2Text_Dataset(speech_valid, transcript_valid),\r\n",
        "    batch_size=args.dev_batch_size, shuffle=True, collate_fn=Speech2Text_collate, **kwargs)\r\n",
        "test_loader = torch.utils.data.DataLoader(\r\n",
        "    Speech2Text_Dataset(speech_test, None),\r\n",
        "    batch_size=1, shuffle=False, collate_fn=Speech2Text_collate, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZtoKUeLY-2l"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7BMnX-DF8EZ"
      },
      "source": [
        "class LockedDropout(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "    def forward(self, x, dropout=0.5):\r\n",
        "        if dropout == 0 or not self.training:\r\n",
        "            return x\r\n",
        "        mask = x.data.new(x.size(0), 1, x.size(2))\r\n",
        "        mask = mask.bernoulli_(1 - dropout)\r\n",
        "        mask = Variable(mask, requires_grad=False) / (1 - dropout)\r\n",
        "        mask = mask.expand_as(x)\r\n",
        "        return mask * x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAFeurc8JU4l"
      },
      "source": [
        "class pBLSTMLayer(nn.Module):\r\n",
        "    def __init__(self, input_feature_dim, hidden_dim, dropout_rate=0.0):\r\n",
        "        super(pBLSTMLayer, self).__init__()\r\n",
        "        self.BLSTM = nn.LSTM(input_feature_dim * 2, hidden_dim, 1, bidirectional=True,\r\n",
        "                                   dropout=dropout_rate, batch_first=True)\r\n",
        "    def forward(self, input_x):\r\n",
        "        batch_size = input_x.size(0)\r\n",
        "        timestep = input_x.size(1)\r\n",
        "        if timestep % 2 != 0:\r\n",
        "            input_x = input_x[:, :-1, :]\r\n",
        "            timestep -= 1\r\n",
        "        feature_dim = input_x.size(2)\r\n",
        "        # Reduce time resolution\r\n",
        "        input_x = input_x.contiguous().view(batch_size, timestep // 2, feature_dim * 2)\r\n",
        "        output, hidden = self.BLSTM(input_x)\r\n",
        "        return output, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu3HZytVJiNu"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, input_feature_dim, hidden_dim, dropout_rate=0.0, dropout=0, dropouth=0, dropouti=0):\r\n",
        "        super(Encoder, self).__init__()\r\n",
        "        self.bn1 = nn.BatchNorm1d(input_feature_dim)\r\n",
        "\r\n",
        "        self.lstm = nn.LSTM(input_size=input_feature_dim,hidden_size=hidden_dim,num_layers=1,bidirectional=True, batch_first=True)\r\n",
        "\r\n",
        "        self.pBLSTM1 = pBLSTMLayer(hidden_dim * 2, hidden_dim,\r\n",
        "                                dropout_rate=dropout_rate)\r\n",
        "        self.pBLSTM2 = pBLSTMLayer(hidden_dim * 2, hidden_dim,\r\n",
        "                                dropout_rate=dropout_rate)\r\n",
        "        self.pBLSTM3 = pBLSTMLayer(hidden_dim * 2, hidden_dim,\r\n",
        "                                dropout_rate=dropout_rate)\r\n",
        "        self.lockdrop = LockedDropout()\r\n",
        "        self.dropouti = dropouti\r\n",
        "        self.dropouth = dropouth\r\n",
        "        self.dropout = dropout\r\n",
        "\r\n",
        "    def forward(self, frames, seq_sizes):\r\n",
        "        frames = frames.permute(1, 2, 0).contiguous()\r\n",
        "        frames = self.bn1(frames)\r\n",
        "        output = frames.permute(0, 2, 1)\r\n",
        "\r\n",
        "        output, _ = self.lstm(output)\r\n",
        "\r\n",
        "        output = self.lockdrop(output, self.dropouti)\r\n",
        "        output, _ = self.pBLSTM1(output)\r\n",
        "        output = self.lockdrop(output, self.dropouth)\r\n",
        "        output, _ = self.pBLSTM2(output)\r\n",
        "        output = self.lockdrop(output, self.dropouth)\r\n",
        "        output, _ = self.pBLSTM3(output)\r\n",
        "        output = self.lockdrop(output, self.dropout)\r\n",
        "\r\n",
        "        # shorten for 8x\r\n",
        "        out_seq_sizes = [size // 8 for size in seq_sizes]\r\n",
        "\r\n",
        "        return output, out_seq_sizes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up3XEtrmKMsq"
      },
      "source": [
        "def SequenceWise(input_module, input_x):\r\n",
        "    batch_size = input_x.size(0)\r\n",
        "    time_steps = input_x.size(1)\r\n",
        "    reshaped_x = input_x.contiguous().view(-1, input_x.size(-1))\r\n",
        "    output_x = input_module(reshaped_x)\r\n",
        "    return output_x.view(batch_size, time_steps, -1)\r\n",
        "\r\n",
        "\r\n",
        "class Attention(nn.Module):\r\n",
        "    def __init__(self, key_query_dim=128, speller_query_dim=256, listener_feature_dim=512, context_dim=128):\r\n",
        "        super(Attention, self).__init__()\r\n",
        "        self.softmax = nn.Softmax(dim=1)\r\n",
        "        self.fc_query = nn.Linear(speller_query_dim, key_query_dim)\r\n",
        "        self.fc_key = nn.Linear(listener_feature_dim, key_query_dim)\r\n",
        "        self.fc_value = nn.Linear(listener_feature_dim, context_dim)\r\n",
        "        self.activate = torch.nn.LeakyReLU(negative_slope=0.2)\r\n",
        "\r\n",
        "    def forward(self, decoder_state, listener_feature, seq_sizes):\r\n",
        "        query = self.activate(self.fc_query(decoder_state))\r\n",
        "        key = self.activate(SequenceWise(self.fc_key, listener_feature))\r\n",
        "        energy = torch.bmm(query.unsqueeze(1), key.transpose(1, 2)).squeeze(dim=1)\r\n",
        "        mask = Variable(energy.data.new(energy.size(0), energy.size(1)).zero_(), requires_grad=False)\r\n",
        "        for i, size in enumerate(seq_sizes):\r\n",
        "            mask[i, :size] = 1\r\n",
        "        attention_score = self.softmax(energy)\r\n",
        "        attention_score = mask * attention_score\r\n",
        "        attention_score = attention_score / torch.sum(attention_score, dim=1).unsqueeze(1).expand_as(attention_score)\r\n",
        "\r\n",
        "        value = self.activate(self.fc_value(listener_feature))\r\n",
        "        context = torch.bmm(attention_score.unsqueeze(1), value).squeeze(dim=1)\r\n",
        "\r\n",
        "        return attention_score, context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJzhG7kcKiOX"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, n_classes, hidden_dim, layer_size, attention, context_dim):\r\n",
        "        super(Decoder, self).__init__()\r\n",
        "        self.n_classes = n_classes\r\n",
        "        self.rnn_unit = nn.LSTMCell\r\n",
        "        self.rnn_layer = torch.nn.ModuleList()\r\n",
        "        \r\n",
        "        self.rnn_layer.append(self.rnn_unit(hidden_dim + context_dim, hidden_dim))\r\n",
        "        rnn_inith = [torch.nn.Parameter(torch.rand(1, hidden_dim))]\r\n",
        "        rnn_initc = [torch.nn.Parameter(torch.rand(1, hidden_dim))]\r\n",
        "\r\n",
        "        for i in range(1, layer_size):\r\n",
        "            self.rnn_layer.append(self.rnn_unit(hidden_dim, hidden_dim))\r\n",
        "            rnn_inith.append(torch.nn.Parameter(torch.rand(1, hidden_dim)))\r\n",
        "            rnn_initc.append(torch.nn.Parameter(torch.rand(1, hidden_dim)))\r\n",
        "        \r\n",
        "        self.rnn_inith = torch.nn.ParameterList(rnn_inith)\r\n",
        "        self.rnn_initc = torch.nn.ParameterList(rnn_initc)\r\n",
        "\r\n",
        "        self.attention = attention\r\n",
        "        self.embed = nn.Embedding(n_classes, hidden_dim, padding_idx=0)\r\n",
        "        self.fc = nn.Linear(hidden_dim + context_dim, hidden_dim)\r\n",
        "        self.activate = torch.nn.LeakyReLU(negative_slope=0.2)\r\n",
        "        self.unembed = nn.Linear(hidden_dim, n_classes)\r\n",
        "        self.unembed.weight = self.embed.weight # Weight Tying\r\n",
        "        self.character_distribution = nn.Sequential(self.fc, self.activate, self.unembed)\r\n",
        "\r\n",
        "    def forward(self, listener_feature, seq_sizes, max_iters, ground_truth=None, teacher_force_rate=0.9, dropout=[]):\r\n",
        "        if ground_truth is None:\r\n",
        "            teacher_force_rate = 0\r\n",
        "\r\n",
        "        batch_size = listener_feature.size()[0]\r\n",
        "        state, output_word = self.get_initial_state(batch_size)\r\n",
        "\r\n",
        "        # dropouts\r\n",
        "        dropout_masks = []\r\n",
        "        if dropout and self.training:\r\n",
        "            h = state[0][0] \r\n",
        "            n_layers = len(state[0])\r\n",
        "            for i in range(n_layers):\r\n",
        "                mask = h.data.new(h.size(0), h.size(1)).bernoulli_(1 - dropout[i]) / (1 - dropout[i])\r\n",
        "                dropout_masks.append(Variable(mask, requires_grad=False))\r\n",
        "\r\n",
        "        raw_pred_seq = []\r\n",
        "        attention_record = []\r\n",
        "        for step in range(ground_truth.size(1) if ground_truth is not None else max_iters):\r\n",
        "\r\n",
        "            attention_score, raw_pred, state = self.get_prediction(listener_feature, seq_sizes, output_word, state, dropout_masks=dropout_masks)\r\n",
        "\r\n",
        "            attention_record.append(attention_score.cpu().detach().numpy())\r\n",
        "            raw_pred_seq.append(raw_pred)\r\n",
        "\r\n",
        "            if np.random.random_sample() < teacher_force_rate:\r\n",
        "                output_word = ground_truth[:, step]\r\n",
        "            else:\r\n",
        "                raw_pred = Gumbel(raw_pred.to('cpu'), torch.tensor([1.0])).sample().cuda()\r\n",
        "                output_word = torch.max(raw_pred, dim=1)[1]\r\n",
        "\r\n",
        "        return torch.stack(raw_pred_seq, dim=1), np.array(attention_record)\r\n",
        "\r\n",
        "    def get_prediction(self, listener_feature, seq_sizes, last_output_word, state, dropout_masks=None):\r\n",
        "        output_word_emb = self.embed(last_output_word)\r\n",
        "        hidden, cell = state[0], state[1]\r\n",
        "        last_rnn_output = hidden[-1]  \r\n",
        "        attention_score, context = self.attention(last_rnn_output, listener_feature, seq_sizes)\r\n",
        "        rnn_input = torch.cat([output_word_emb, context], dim=1)\r\n",
        "        new_hidden, new_cell = [None] * len(self.rnn_layer), [None] * len(self.rnn_layer)\r\n",
        "        for l, rnn in enumerate(self.rnn_layer):\r\n",
        "            new_hidden[l], new_cell[l] = rnn(rnn_input, (hidden[l], cell[l]))\r\n",
        "            if dropout_masks:\r\n",
        "                rnn_input = new_hidden[l] * dropout_masks[l]\r\n",
        "            else:\r\n",
        "                rnn_input = new_hidden[l]\r\n",
        "        rnn_output = new_hidden[-1]  \r\n",
        "        concat_feature = torch.cat([rnn_output, context], dim=1)\r\n",
        "        raw_pred = self.character_distribution(concat_feature)\r\n",
        "        return attention_score, raw_pred, [new_hidden, new_cell]\r\n",
        "\r\n",
        "    def get_initial_state(self, batch_size):\r\n",
        "        hidden = [h.repeat(batch_size, 1) for h in self.rnn_inith]\r\n",
        "        cell = [c.repeat(batch_size, 1) for c in self.rnn_initc]\r\n",
        "        output_word = Variable(hidden[0].data.new(batch_size).long().fill_(chr2idx['<eos>']))\r\n",
        "        return [hidden, cell], output_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOFpV0ljOmma"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Seq2Seq, self).__init__()\r\n",
        "        self.listener = Encoder(40, args.hidden_dim, dropouti=args.dropouti, dropouth=args.dropouth, dropout=args.dropout)\r\n",
        "        self.attention = Attention(key_query_dim=args.key_query_dim, speller_query_dim=args.hidden_dim, listener_feature_dim=args.listener_feature_dim, context_dim=args.context_dim)\r\n",
        "        self.speller = Decoder(len(idx2chr), args.hidden_dim, 3, self.attention, context_dim=args.context_dim) \r\n",
        "\r\n",
        "    def forward(self, frames, seq_sizes, labels, max_iters=args.max_iters):\r\n",
        "        listener_features, out_seq_sizes = self.listener(frames, seq_sizes)\r\n",
        "        outputs, attentions = self.speller(listener_features, out_seq_sizes, max_iters, labels,\r\n",
        "                                           teacher_force_rate=0.9, dropout=[0.2, 0.2, 0.3])\r\n",
        "        return outputs, attentions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCL7R0vQZDa9"
      },
      "source": [
        "## Sequence to Sequence Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKz24FzOyj1F"
      },
      "source": [
        "def find_first_eos_in_pred(pred):\r\n",
        "    chrs = pred.max(1)[1].data.cpu().numpy()\r\n",
        "    for idx, c in enumerate(chrs):\r\n",
        "        if c == chr2idx['<eos>']:\r\n",
        "            return idx\r\n",
        "    return len(chrs)\r\n",
        "\r\n",
        "class SequenceCrossEntropyLoss(torch.nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "    def forward(self, preds, label_sizes, labels):\r\n",
        "        pred_list = []\r\n",
        "        label_list = []\r\n",
        "        max_iter = preds.size(1)\r\n",
        "        for (pred, label, num_iter) in zip(preds, labels, label_sizes):\r\n",
        "            pred_for_loss = []\r\n",
        "            label_for_loss = []\r\n",
        "            eos_idx = find_first_eos_in_pred(pred)\r\n",
        "\r\n",
        "            if eos_idx < num_iter:\r\n",
        "                if eos_idx != 0:\r\n",
        "                    pred_for_loss.append(pred[:eos_idx])\r\n",
        "                pred_for_loss += [pred[eos_idx:eos_idx + 1]] * (num_iter - eos_idx)\r\n",
        "                label_for_loss.append(label[:num_iter])\r\n",
        "\r\n",
        "            elif eos_idx == max_iter:\r\n",
        "                pred_for_loss.append(pred[:eos_idx])\r\n",
        "                label_for_loss.append(label[:num_iter])\r\n",
        "                label_for_loss += [label[num_iter - 1:num_iter]] * (eos_idx - num_iter)\r\n",
        "\r\n",
        "            else:\r\n",
        "                pred_for_loss.append(pred[:eos_idx + 1])\r\n",
        "                label_for_loss.append(label[:num_iter])\r\n",
        "                label_for_loss += [label[num_iter - 1:num_iter]] * (eos_idx + 1 - num_iter)\r\n",
        "\r\n",
        "            pred_list.append(torch.cat(pred_for_loss))\r\n",
        "            label_list.append(torch.cat(label_for_loss))\r\n",
        "\r\n",
        "        preds_batch = torch.cat(pred_list)\r\n",
        "        labels_batch = torch.cat(label_list)\r\n",
        "        loss = torch.nn.functional.cross_entropy(preds_batch, labels_batch, reduction='sum')\r\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znuTmkVdZoCS"
      },
      "source": [
        "## Train Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WzhTdmuO6IL"
      },
      "source": [
        "def train(epoch, model, optimizer, criterion, loader):\r\n",
        "    model.train()\r\n",
        "    sum_loss, sum_labels = 0, 0\r\n",
        "    start_time = time.time()\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    for batch, (frames, seq_sizes, labels, label_sizes) in enumerate(loader):\r\n",
        "        batch += 1\r\n",
        "        sum_labels += sum(label_sizes)\r\n",
        "\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            frames, labels = frames.cuda(), labels.cuda()\r\n",
        "        frames, labels = Variable(frames), Variable(labels)\r\n",
        "\r\n",
        "        outputs, attentions = model(frames, seq_sizes, labels)\r\n",
        "        loss = criterion(outputs, label_sizes, labels)\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        sum_loss += loss.item() \r\n",
        "\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\r\n",
        "\r\n",
        "        optimizer.step()\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        if batch % args.log_interval == 0:\r\n",
        "            plot_grad_flow(model.named_parameters(), 'grad_flow.png')\r\n",
        "            elapsed = time.time() - start_time\r\n",
        "            avg_loss = sum_loss / sum_labels\r\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches ({:5.2f}%) | lr {:.2e} | {:3.0f} ms/utter | loss/utter {:5.2f} | loss/label {:5.4f}'\r\n",
        "                    .format(epoch, batch, len(loader), (100.0 * batch / len(loader)),\r\n",
        "                            optimizer.param_groups[0]['lr'],\r\n",
        "                            elapsed * 1000.0 / (args.log_interval * args.train_batch_size),\r\n",
        "                            sum_loss / (args.log_interval * args.train_batch_size),\r\n",
        "                            avg_loss))\r\n",
        "            sum_loss, sum_labels = 0, 0\r\n",
        "            start_time = time.time()\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opo7bTY2Zr-0"
      },
      "source": [
        "## Validation Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRHMZHl_ydEg"
      },
      "source": [
        "def evaluate(model, criterion, loader):\r\n",
        "    model.eval()\r\n",
        "    total_loss = 0\r\n",
        "    total_cer = 0\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      for batch, (frames, seq_sizes, labels, label_sizes) in enumerate(loader):\r\n",
        "          if args.cuda:\r\n",
        "              frames, labels = frames.cuda(), labels.cuda()\r\n",
        "          frames, labels = Variable(frames), Variable(labels)\r\n",
        "\r\n",
        "          outputs, attentions = model(frames, seq_sizes, labels)\r\n",
        "          loss = criterion(outputs, label_sizes, labels)\r\n",
        "\r\n",
        "          total_loss += loss.item() \r\n",
        "\r\n",
        "          decoded = greedy_decode(outputs)\r\n",
        "          labels_str = labels2str(to_np(labels), label_sizes) \r\n",
        "          for l, m in zip(labels_str, decoded):\r\n",
        "              e = cer(l, m)\r\n",
        "              total_cer += e\r\n",
        "\r\n",
        "          if batch % args.log_interval == 0:        \r\n",
        "            print(attentions.shape)\r\n",
        "            attentions = np.squeeze(attentions, axis=1)\r\n",
        "            plt.matshow(attentions)\r\n",
        "            plt.show()\r\n",
        "\r\n",
        "    total_labels = loader.dataset.total_labels\r\n",
        "    return total_loss / (len(loader) * args.dev_batch_size), total_loss / total_labels, total_cer * 100.0 / total_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yws--3OoZx-h"
      },
      "source": [
        "## Training & Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzt73-p0pZfZ"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwVKGPQsPBbe"
      },
      "source": [
        "np.random.seed(args.seed)\r\n",
        "torch.manual_seed(args.seed)\r\n",
        "if args.cuda:\r\n",
        "  torch.cuda.manual_seed(args.seed)\r\n",
        "\r\n",
        "best_cer = 9999.9999\r\n",
        "model = Seq2Seq()\r\n",
        "#model.load_state_dict(torch.load(args.weights_dir+\"/009_48.8567.w\"))\r\n",
        "if args.cuda:\r\n",
        "  model.cuda()\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wdecay)\r\n",
        "criterion = SequenceCrossEntropyLoss()\r\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, threshold=0.01, verbose=True)\r\n",
        "for epoch in range(1, args.epochs):\r\n",
        "    epoch_start_time = time.time()\r\n",
        "    train(epoch, model, optimizer, criterion, train_loader)\r\n",
        "\r\n",
        "    val_loss_utter, val_loss_label, val_cer = evaluate(model, criterion, dev_loader)\r\n",
        "    scheduler.step(val_loss_label)\r\n",
        "    print('=' * 100)\r\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | loss/utter {:5.2f} | loss/label {:5.4f} | valid cer {:5.4f}'\r\n",
        "          .format(epoch, (time.time() - epoch_start_time), val_loss_utter, val_loss_label, val_cer))\r\n",
        "    print('=' * 100)\r\n",
        "\r\n",
        "    if not os.path.exists(args.weights_dir):\r\n",
        "        os.makedirs(args.weights_dir)\r\n",
        "    if val_cer < best_cer:  \r\n",
        "        best_cer = val_cer\r\n",
        "        weight_fname = \"{}/{:03d}_{}.w\".format(args.weights_dir, epoch, \"{:.4f}\".format(val_cer))\r\n",
        "        print(\"saving as\", weight_fname)\r\n",
        "        torch.save(model.state_dict(), weight_fname)\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QSAESTcQNxQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uloWQEA-46b1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O-sd8oObYJa"
      },
      "source": [
        "## Predict & Create Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xKAWBCy46e0"
      },
      "source": [
        "def greedySearch(probs):\r\n",
        "    out = []\r\n",
        "    for prob in probs:\r\n",
        "        s = []\r\n",
        "        for step in prob:\r\n",
        "            idx = torch.argmax(step).item()\r\n",
        "            c = idx2chr[idx]\r\n",
        "            if c == '<eos>':\r\n",
        "                break\r\n",
        "            s.append(c)\r\n",
        "        out.append(\"\".join(s))\r\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYu3wUZc6l4j"
      },
      "source": [
        "def predict(args, csv_fpath, weights_fpath):\r\n",
        "    model = Seq2Seq()\r\n",
        "    model.load_state_dict(torch.load(weights_fpath))\r\n",
        "    if args.cuda:\r\n",
        "        model.cuda()\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    with open(csv_fpath, 'w') as csvfile:\r\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=['id', 'label'])\r\n",
        "        writer.writeheader()\r\n",
        "        cnt = 0\r\n",
        "        with torch.no_grad():\r\n",
        "          for batch, (frames, seq_sizes, _, _) in enumerate(test_loader):\r\n",
        "              if args.cuda:\r\n",
        "                  frames = frames.cuda()\r\n",
        "              frames = Variable(frames)\r\n",
        "              outputs, attentions = model(frames, seq_sizes, None)\r\n",
        "              decoded = greedySearch(outputs)\r\n",
        "              s = decoded[0]\r\n",
        "              while s.find('  ') != -1:\r\n",
        "                s = s.replace('  ', ' ')\r\n",
        "              if cnt % args.log_interval == 0:\r\n",
        "                  print(cnt, s)\r\n",
        "              writer.writerow({\"id\": cnt, \"label\": s})\r\n",
        "              cnt += 1\r\n",
        "\r\n",
        "    print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycRpVEWI7N7k"
      },
      "source": [
        "predict(args, \"submission.csv\", args.weights_dir+\"/009_28.1937.w\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksXpok0hW-9z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}